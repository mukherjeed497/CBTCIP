# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nSWam2dZ8P8IimBkeui7jEwryuGUHvNr
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_iris
iris = load_iris()

dir(iris)

iris.feature_names

iris.target_names

df = pd.DataFrame(data = iris.data, columns = iris.feature_names)
df.head()

df['target'] = iris.target
df.head()

iris.target_names

df[df.target==1].head()

df[df.target==2].head()

"""generating new column from existing column using apply function"""

df['flower_name'] = df.target.apply(lambda x: iris.target_names[x])

df.head()

df.describe()

df.info()

# to display no. of samples on each class
df['flower_name'].value_counts()

"""Preprocessing the dataset"""

# check for null values
df.isnull().sum()

"""Exploratoty Data Analysis"""

df['sepal length (cm)'].hist()

df['sepal width (cm)'].hist()

df['petal length (cm)'].hist()

df['petal width (cm)'].hist()

# Commented out IPython magic to ensure Python compatibility.
# magic command for inline ploting
# %matplotlib inline

# seperating dataframe
df0 = df[df.target==0]
df1 = df[df.target==1]
df2 = df[df.target==2]

df2.head()

colors = ['red', 'orange', 'blue']
flower_name = ['virginica', 'versicolor', 'setosa']

for i in range(3):
  x = df[df['flower_name'] == flower_name[i]]
  plt.scatter(x['sepal length (cm)'], x['sepal width (cm)'], c = colors[i], label=flower_name[i])
plt.xlabel("Sepal Length")
plt.ylabel("Sepal width")
plt.legend()

for i in range(3):
  x = df[df['flower_name'] == flower_name[i]]
  plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c = colors[i], label=flower_name[i])
plt.xlabel("Petal Length")
plt.ylabel("Petal width")
plt.legend()

for i in range(3):
  x = df[df['flower_name'] == flower_name[i]]
  plt.scatter(x['sepal length (cm)'], x['petal length (cm)'], c = colors[i], label=flower_name[i])
plt.xlabel("Sepal Length")
plt.ylabel("Petal Length")
plt.legend()

for i in range(3):
  x = df[df['flower_name'] == flower_name[i]]
  plt.scatter(x['sepal width (cm)'], x['petal width (cm)'], c = colors[i], label=flower_name[i])
plt.xlabel("Sepal Width")
plt.ylabel("Petal width")
plt.legend()



plt.scatter(df0['sepal length (cm)'],df0['sepal width (cm)'], color='green',marker='+')
plt.xlabel('sepal Length (cm)')
plt.ylabel("sepal width (cm)")
plt.title('Scatter plot of Sepal Length vs. Sepal Width')
plt.show()



plt.scatter(df1['sepal length (cm)'],df1['sepal width (cm)'], color='green',marker='+')
plt.xlabel('sepal Length (cm)')
plt.ylabel("sepal width (cm)")
plt.title('Scatter plot of Sepal Length vs. Sepal Width')
plt.show()

plt.scatter(df2['sepal length (cm)'],df2['sepal width (cm)'], color='green',marker='+')
plt.xlabel('sepal Length (cm)')
plt.ylabel("sepal width (cm)")
plt.title('Scatter plot of Sepal Length vs. Sepal Width')
plt.show()

plt.xlabel('sepal Length (cm)')
plt.ylabel("sepal width (cm)")
plt.scatter(df0['sepal length (cm)'],df0['sepal width (cm)'], color='green',marker='+')
plt.scatter(df1['sepal length (cm)'],df1['sepal width (cm)'], color='blue',marker='_')
plt.title('Scatter plot of Sepal Length vs. Sepal Width')

plt.xlabel('Petal Length (cm)')
plt.ylabel("Petal width (cm)")
plt.scatter(df0['petal length (cm)'],df0['petal width (cm)'], color='green',marker='+')
plt.scatter(df1['petal length (cm)'],df1['petal width (cm)'], color='blue',marker='_')
plt.title('Scatter plot of petal Length vs. petal Width')

df.corr()

corr = df.corr()
fig, ax = plt.subplots(figsize=(5,5))
sns.heatmap(corr, annot=True, ax = ax, cmap = "coolwarm")

"""Label Encoder"""



"""Model Training"""

from sklearn.model_selection import train_test_split

X = df.drop(['target','flower_name'],axis='columns')

X

y = df['target']

y

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

len(X_train)

from sklearn.linear_model import LogisticRegression
log = LogisticRegression(max_iter=1000)

log.fit(X_train,y_train)

print("Accuracy:", log.score(X_test, y_test)*100)

from sklearn.neighbors import KNeighborsClassifier
KNN = KNeighborsClassifier()

KNN.fit(X_train,y_train)

print("Accuracy:", KNN.score(X_test, y_test)*100)

from sklearn.svm import SVC
# model = SVC(C=1000)
#model = SVC(gamma=100)
SVC_model = SVC(kernel = 'linear')

SVC_model.fit(X_train,y_train)

print("Accuracy:", SVC_model.score(X_test, y_test)*100)

import  numpy as np
input_data = (5.8,	2.7,	5.1,	1.9)
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting only on instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = SVC_model.predict(input_data_reshaped)
print(prediction)
if prediction[0] == 0:
  print("setosa")
elif prediction[0]==1:
  print('versicolor')
elif prediction[0] ==2:
  print('virginica')